{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import libraries\n",
    "2. Import dataset\n",
    "3. Perform feature engineering\n",
    "    a. Combine spkts and dpkts\n",
    "    b. Perform log transform on features with skewed distribution and remove original features\n",
    "4. Standardization\n",
    "5. One hot encoding\n",
    "6. Prepare data prep pipeline\n",
    "7. Prepare and validate train and test datasets\n",
    "8. Split train and test datset into X_train and y_train.\n",
    "9. Baseline modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dataset_path = 'dataset'\n",
    "saved_files_path = 'saved_files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = pickle.load(open(saved_files_path+'final_train_complete.pkl', 'rb'))\n",
    "X_test, y_test = pickle.load(open(saved_files_path+'final_test_complete.pkl', 'rb'))\n",
    "\n",
    "# Parametrs\n",
    "saved_parameters = pickle.load(open(saved_files_path+'saved_params.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2032034, 41)\n",
      "(508009, 42)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before dropping highly correlated features:  (2032034, 41)\n",
      "Shape after dropping highly correlated features:  (2032034, 38)\n",
      "All the columns present in the dataset are:  Index(['proto', 'state', 'dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss',\n",
      "       'service', 'sload', 'dload', 'spkts', 'swin', 'stcpb', 'dtcpb', 'smean',\n",
      "       'dmean', 'trans_depth', 'response_body_len', 'sjit', 'djit', 'sinpkt',\n",
      "       'dinpkt', 'tcprtt', 'synack', 'ackdat', 'is_sm_ips_ports',\n",
      "       'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd',\n",
      "       'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ltm',\n",
      "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#Drop highly correlated data points\n",
    "#Code reference: https://chrisalbon.com/code/machine_learning/feature_selection/drop_highly_correlated_features/\n",
    "\n",
    "print(\"Shape before dropping highly correlated features: \",X_train.shape)\n",
    "\n",
    "# Create correlation matrix\n",
    "feat_corr = X_train.corr(method='pearson').abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper_traingle = feat_corr.where(np.triu(np.ones(feat_corr.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find features with correlation greater than 0.98\n",
    "columns_to_drop = [column for column in upper_traingle.columns if any(upper_traingle[column] > 0.98)]\n",
    "#Adding attack_categories column because we are building binary classification dataset\n",
    "#columns_to_drop.append('attack_cat')\n",
    "\n",
    "# Drop features \n",
    "X_train.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "#Dictionary to store parameters\n",
    "saved_parameters['cols_to_drop'] = columns_to_drop\n",
    "saved_parameters['columns_in_train'] = X_train.columns\n",
    "\n",
    "print(\"Shape after dropping highly correlated features: \",X_train.shape)\n",
    "print(\"All the columns present in the dataset are: \",X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility  functions\n",
    "def get_multi_corr(data):\n",
    "    '''\n",
    "    function to return the correlation values of each feature with each other\n",
    "    '''\n",
    "    return data.corr()\n",
    "\n",
    "def get_corr_between_cols(data, y, col1, col2='label'):\n",
    "    '''\n",
    "    Function to return correlation value with the label feature\n",
    "    '''\n",
    "    return round(data[col1].corr(y),4)\n",
    "\n",
    "def get_corr_with_log1p_transformation_with_label(data, y, col1, col2='label'):\n",
    "    '''\n",
    "    Function to return the correlation value with the log1p transformation \n",
    "    '''\n",
    "    return round(data[col1].apply(np.log1p).corr(y), 4)\n",
    "\n",
    "def get_numeric_data_column_list(data):\n",
    "    '''\n",
    "    Function to return the list of numerical data\n",
    "    '''\n",
    "    df = list(data.select_dtypes(include='number').columns)\n",
    "    #df.remove('id')\n",
    "    df.remove('is_ftp_login')\n",
    "    df.remove('is_sm_ips_ports')\n",
    "    #df.remove('label')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature set 1\n",
    " 1. Total bytes from source and destination -> sbytes+dbytes\n",
    " 2. Total load from source and destination -> sload+dload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sloss</th>\n",
       "      <th>service</th>\n",
       "      <th>sload</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>total_bytes</th>\n",
       "      <th>total_load</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921074</th>\n",
       "      <td>udp</td>\n",
       "      <td>INT</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dns</td>\n",
       "      <td>1.508571e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>264</td>\n",
       "      <td>1.508571e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012474</th>\n",
       "      <td>udp</td>\n",
       "      <td>INT</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dns</td>\n",
       "      <td>1.508571e+08</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>264</td>\n",
       "      <td>1.508571e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115171</th>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>1.033946</td>\n",
       "      <td>1684</td>\n",
       "      <td>10168</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>http</td>\n",
       "      <td>1.210121e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11852</td>\n",
       "      <td>8.641070e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164402</th>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>dns</td>\n",
       "      <td>5.799404e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>1.286991e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889220</th>\n",
       "      <td>udp</td>\n",
       "      <td>INT</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dns</td>\n",
       "      <td>5.066666e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "      <td>36</td>\n",
       "      <td>114</td>\n",
       "      <td>5.066666e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        proto state       dur  sbytes  dbytes  sttl  dttl  sloss service  \\\n",
       "1921074   udp   INT  0.000007     264       0    60     0      0     dns   \n",
       "2012474   udp   INT  0.000007     264       0    60     0      0     dns   \n",
       "115171    tcp   FIN  1.033946    1684   10168    31    29      3    http   \n",
       "2164402   udp   CON  0.001007     146     178    31    29      0     dns   \n",
       "1889220   udp   INT  0.000009     114       0   254     0      0     dns   \n",
       "\n",
       "                sload  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst  ct_dst_ltm  \\\n",
       "1921074  1.508571e+08  ...           0          22          22          14   \n",
       "2012474  1.508571e+08  ...           0          19          19          19   \n",
       "115171   1.210121e+04  ...           0           1           1           2   \n",
       "2164402  5.799404e+05  ...           0           4           1           3   \n",
       "1889220  5.066666e+07  ...           0          36          36          31   \n",
       "\n",
       "         ct_src_ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
       "1921074          14                14                14              22   \n",
       "2012474          19                19                19              19   \n",
       "115171            2                 1                 1               1   \n",
       "2164402           4                 2                 1               2   \n",
       "1889220          31                31                18              36   \n",
       "\n",
       "         total_bytes    total_load  \n",
       "1921074          264  1.508571e+08  \n",
       "2012474          264  1.508571e+08  \n",
       "115171         11852  8.641070e+04  \n",
       "2164402          324  1.286991e+06  \n",
       "1889220          114  5.066666e+07  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['total_bytes'] = X_train['sbytes']+X_train['dbytes']\n",
    "X_train['total_load'] = X_train['sload'] + X_train['dload']\n",
    "#X_train = X_train.drop('Unnamed: 0', axis=1) \n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering - technique 2 - applying log1p transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  dur  with label.\n",
      "Normal Correlation:  -0.0792\n",
      "Log1p Correlation:  -0.104\n",
      "Absolute difference between normal and log1p correlation:  0.0248\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  sbytes  with label.\n",
      "Normal Correlation:  -0.1694\n",
      "Log1p Correlation:  -0.3968\n",
      "Absolute difference between normal and log1p correlation:  0.2274\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  dbytes  with label.\n",
      "Normal Correlation:  -0.0943\n",
      "Log1p Correlation:  -0.5539\n",
      "Absolute difference between normal and log1p correlation:  0.4596\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  sttl  with label.\n",
      "Normal Correlation:  0.9252\n",
      "Log1p Correlation:  0.9095\n",
      "Absolute difference between normal and log1p correlation:  0.0157\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  dttl  with label.\n",
      "Normal Correlation:  0.0469\n",
      "Log1p Correlation:  -0.541\n",
      "Absolute difference between normal and log1p correlation:  0.4941\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  sloss  with label.\n",
      "Normal Correlation:  -0.2423\n",
      "Log1p Correlation:  -0.3156\n",
      "Absolute difference between normal and log1p correlation:  0.0733\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  sload  with label.\n",
      "Normal Correlation:  0.2792\n",
      "Log1p Correlation:  0.4112\n",
      "Absolute difference between normal and log1p correlation:  0.132\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  dload  with label.\n",
      "Normal Correlation:  -0.2468\n",
      "Log1p Correlation:  -0.6479\n",
      "Absolute difference between normal and log1p correlation:  0.4011\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  spkts  with label.\n",
      "Normal Correlation:  -0.1898\n",
      "Log1p Correlation:  -0.3333\n",
      "Absolute difference between normal and log1p correlation:  0.1435\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  swin  with label.\n",
      "Normal Correlation:  -0.3165\n",
      "Log1p Correlation:  -0.3165\n",
      "Absolute difference between normal and log1p correlation:  0.0\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  stcpb  with label.\n",
      "Normal Correlation:  -0.2163\n",
      "Log1p Correlation:  -0.3134\n",
      "Absolute difference between normal and log1p correlation:  0.0971\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  dtcpb  with label.\n",
      "Normal Correlation:  -0.2003\n",
      "Log1p Correlation:  -0.3115\n",
      "Absolute difference between normal and log1p correlation:  0.1112\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  smean  with label.\n",
      "Normal Correlation:  -0.1465\n",
      "Log1p Correlation:  -0.2364\n",
      "Absolute difference between normal and log1p correlation:  0.0899\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  dmean  with label.\n",
      "Normal Correlation:  -0.2949\n",
      "Log1p Correlation:  -0.6\n",
      "Absolute difference between normal and log1p correlation:  0.3051\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  trans_depth  with label.\n",
      "Normal Correlation:  -0.0206\n",
      "Log1p Correlation:  -0.0206\n",
      "Absolute difference between normal and log1p correlation:  0.0\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  response_body_len  with label.\n",
      "Normal Correlation:  -0.0605\n",
      "Log1p Correlation:  -0.0396\n",
      "Absolute difference between normal and log1p correlation:  0.0209\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  sjit  with label.\n",
      "Normal Correlation:  -0.0716\n",
      "Log1p Correlation:  -0.2065\n",
      "Absolute difference between normal and log1p correlation:  0.1349\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  djit  with label.\n",
      "Normal Correlation:  -0.0737\n",
      "Log1p Correlation:  -0.1997\n",
      "Absolute difference between normal and log1p correlation:  0.126\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  sinpkt  with label.\n",
      "Normal Correlation:  -0.0325\n",
      "Log1p Correlation:  -0.0974\n",
      "Absolute difference between normal and log1p correlation:  0.0649\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  dinpkt  with label.\n",
      "Normal Correlation:  0.0348\n",
      "Log1p Correlation:  -0.0804\n",
      "Absolute difference between normal and log1p correlation:  0.0456\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  tcprtt  with label.\n",
      "Normal Correlation:  0.2297\n",
      "Log1p Correlation:  0.2307\n",
      "Absolute difference between normal and log1p correlation:  0.001\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  ackdat  with label.\n",
      "Normal Correlation:  0.2062\n",
      "Log1p Correlation:  0.208\n",
      "Absolute difference between normal and log1p correlation:  0.0018\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  ct_state_ttl  with label.\n",
      "Normal Correlation:  0.9704\n",
      "Log1p Correlation:  0.9734\n",
      "Absolute difference between normal and log1p correlation:  0.003\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  ct_srv_src  with label.\n",
      "Normal Correlation:  0.4823\n",
      "Log1p Correlation:  0.4077\n",
      "Absolute difference between normal and log1p correlation:  0.0746\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  ct_srv_dst  with label.\n",
      "Normal Correlation:  0.4602\n",
      "Log1p Correlation:  0.3714\n",
      "Absolute difference between normal and log1p correlation:  0.0888\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  ct_dst_ltm  with label.\n",
      "Normal Correlation:  0.4117\n",
      "Log1p Correlation:  0.3337\n",
      "Absolute difference between normal and log1p correlation:  0.078\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  ct_src_ltm  with label.\n",
      "Normal Correlation:  0.4269\n",
      "Log1p Correlation:  0.3691\n",
      "Absolute difference between normal and log1p correlation:  0.0578\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  ct_src_dport_ltm  with label.\n",
      "Normal Correlation:  0.4817\n",
      "Log1p Correlation:  0.5078\n",
      "Absolute difference between normal and log1p correlation:  0.0261\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  ct_dst_sport_ltm  with label.\n",
      "Normal Correlation:  0.4332\n",
      "Log1p Correlation:  0.4908\n",
      "Absolute difference between normal and log1p correlation:  0.0576\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  ct_dst_src_ltm  with label.\n",
      "Normal Correlation:  0.5322\n",
      "Log1p Correlation:  0.5404\n",
      "Absolute difference between normal and log1p correlation:  0.0082\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  total_bytes  with label.\n",
      "Normal Correlation:  -0.1\n",
      "Log1p Correlation:  -0.445\n",
      "Absolute difference between normal and log1p correlation:  0.345\n",
      "--------------------------------------------------------------------------------\n",
      "Correlation for feature:  total_load  with label.\n",
      "Normal Correlation:  0.2673\n",
      "Log1p Correlation:  0.3219\n",
      "Absolute difference between normal and log1p correlation:  0.0546\n"
     ]
    }
   ],
   "source": [
    "#For all the numeric columns for which the correlation with label feature increases on applying log1p transformation we will transform it to their log 1p value\n",
    "\n",
    "#Get the numeric features\n",
    "numeric_cols = get_numeric_data_column_list(X_train)\n",
    "abs_difference = {}\n",
    "for col in numeric_cols:\n",
    "    print(\"-\"*80)\n",
    "    print(\"Correlation for feature: \",col,\" with label.\")\n",
    "    print(\"Normal Correlation: \", get_corr_between_cols(X_train, y_train, col))\n",
    "    print(\"Log1p Correlation: \",get_corr_with_log1p_transformation_with_label(X_train, y_train, col))\n",
    "    print(\"Absolute difference between normal and log1p correlation: \", round(np.abs(np.abs(get_corr_between_cols(X_train, y_train, col)) - np.abs(get_corr_with_log1p_transformation_with_label(X_train, y_train, col))),4))\n",
    "    abs_difference[col] = round(np.abs(np.abs(get_corr_between_cols(X_train, y_train, col)) - np.abs(get_corr_with_log1p_transformation_with_label(X_train, y_train, col))),4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns for which correlation is high and we would transform them by applying log1p transform\n",
    "cols_for_log1p = ['dur', 'sbytes', 'dbytes', 'sloss', 'spkts', 'dload', 'dttl', 'sload', 'dload', 'sinpkt', 'dinpkt', 'dmean', 'sjit', 'djit']\n",
    "\n",
    "#Saving these parameters in saved parameters dictionary\n",
    "saved_parameters['cols_for_log1p'] = set(set(X_train.columns).intersection(set(cols_for_log1p)))-set(saved_parameters['cols_to_drop'])\n",
    "#Saving the saved parameters dictionary in a pickle file\n",
    "pickle.dump(saved_parameters, open(os.path.join(saved_files_path,'saved_parameters.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log1p_transform(data):\n",
    "    '''\n",
    "    This function transforms the columns stored in the saved parameters dictionary by applying log1p transform and returns the data.\n",
    "    '''\n",
    "    #Loading the saved columns\n",
    "    saved_parameters = pickle.load(open(saved_files_path+'saved_parameters.pkl', 'rb'))\n",
    "    \n",
    "    #Getting the names of the columns for which we need to apply log1p \n",
    "    log1p_cols = saved_parameters['cols_for_log1p']\n",
    "    \n",
    "    #Transforming the log1p functions\n",
    "    for col in log1p_cols:\n",
    "        transformed_col = col+'_log1p'\n",
    "        data[transformed_col] = data[col].apply(np.log1p)\n",
    "        data = data.drop([col], axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2032034, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>sttl</th>\n",
       "      <th>service</th>\n",
       "      <th>swin</th>\n",
       "      <th>stcpb</th>\n",
       "      <th>dtcpb</th>\n",
       "      <th>smean</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>response_body_len</th>\n",
       "      <th>...</th>\n",
       "      <th>dload_log1p</th>\n",
       "      <th>sinpkt_log1p</th>\n",
       "      <th>dinpkt_log1p</th>\n",
       "      <th>sbytes_log1p</th>\n",
       "      <th>sload_log1p</th>\n",
       "      <th>sjit_log1p</th>\n",
       "      <th>dur_log1p</th>\n",
       "      <th>spkts_log1p</th>\n",
       "      <th>dmean_log1p</th>\n",
       "      <th>djit_log1p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1921074</th>\n",
       "      <td>udp</td>\n",
       "      <td>INT</td>\n",
       "      <td>60</td>\n",
       "      <td>dns</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.579730</td>\n",
       "      <td>18.831844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012474</th>\n",
       "      <td>udp</td>\n",
       "      <td>INT</td>\n",
       "      <td>60</td>\n",
       "      <td>dns</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.579730</td>\n",
       "      <td>18.831844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115171</th>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>31</td>\n",
       "      <td>http</td>\n",
       "      <td>255</td>\n",
       "      <td>600762523</td>\n",
       "      <td>601772495</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>3924</td>\n",
       "      <td>...</td>\n",
       "      <td>11.216007</td>\n",
       "      <td>4.388330</td>\n",
       "      <td>4.123740</td>\n",
       "      <td>7.429521</td>\n",
       "      <td>9.401144</td>\n",
       "      <td>9.079867</td>\n",
       "      <td>0.709978</td>\n",
       "      <td>2.708050</td>\n",
       "      <td>6.338594</td>\n",
       "      <td>8.946974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164402</th>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>31</td>\n",
       "      <td>dns</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.468859</td>\n",
       "      <td>0.003992</td>\n",
       "      <td>0.006976</td>\n",
       "      <td>4.990433</td>\n",
       "      <td>13.270682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>4.499810</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1889220</th>\n",
       "      <td>udp</td>\n",
       "      <td>INT</td>\n",
       "      <td>254</td>\n",
       "      <td>dns</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.744932</td>\n",
       "      <td>17.740779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        proto state  sttl service  swin      stcpb      dtcpb  smean  \\\n",
       "1921074   udp   INT    60     dns     0          0          0    132   \n",
       "2012474   udp   INT    60     dns     0          0          0    132   \n",
       "115171    tcp   FIN    31    http   255  600762523  601772495    120   \n",
       "2164402   udp   CON    31     dns     0          0          0     73   \n",
       "1889220   udp   INT   254     dns     0          0          0     57   \n",
       "\n",
       "         trans_depth  response_body_len  ...  dload_log1p  sinpkt_log1p  \\\n",
       "1921074            0                  0  ...     0.000000      0.006976   \n",
       "2012474            0                  0  ...     0.000000      0.006976   \n",
       "115171             1               3924  ...    11.216007      4.388330   \n",
       "2164402            0                  0  ...    13.468859      0.003992   \n",
       "1889220            0                  0  ...     0.000000      0.008960   \n",
       "\n",
       "         dinpkt_log1p  sbytes_log1p  sload_log1p  sjit_log1p  dur_log1p  \\\n",
       "1921074      0.000000      5.579730    18.831844    0.000000   0.000007   \n",
       "2012474      0.000000      5.579730    18.831844    0.000000   0.000007   \n",
       "115171       4.123740      7.429521     9.401144    9.079867   0.709978   \n",
       "2164402      0.006976      4.990433    13.270682    0.000000   0.001006   \n",
       "1889220      0.000000      4.744932    17.740779    0.000000   0.000009   \n",
       "\n",
       "         spkts_log1p  dmean_log1p  djit_log1p  \n",
       "1921074     1.098612     0.000000    0.000000  \n",
       "2012474     1.098612     0.000000    0.000000  \n",
       "115171      2.708050     6.338594    8.946974  \n",
       "2164402     1.098612     4.499810    0.000000  \n",
       "1889220     1.098612     0.000000    0.000000  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying the log1p transform on the train data\n",
    "X_train = log1p_transform(X_train)\n",
    "print(X_train.shape)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing - Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching all the numeric features to standardize them\n",
    "result_numeric = list(X_train.select_dtypes(include='number').columns)\n",
    "\n",
    "#Removing the names of the columns for which standardization is not required\n",
    "for i in saved_parameters['binary_cols']:\n",
    "    result_numeric.remove(i)\n",
    "\n",
    "#Using the standard scaler from sklearn library\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train[result_numeric])\n",
    "\n",
    "#Dumping the scaler object in pickle file\n",
    "pickle.dump(scaler, open(os.path.join(saved_files_path,'scaler_2.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data pipeline function\n",
    "#Standard scaler on data\n",
    "def scale_data(data):\n",
    "    '''\n",
    "    This function standardize the numerical columns\n",
    "    '''\n",
    "    #Using Standard Scaler from sklearn preprocessing to scale our numeric features\n",
    "    scaler = pickle.load(open(saved_files_path+'scaler_2.pkl', 'rb'))\n",
    "\n",
    "    result_numeric = list(data.select_dtypes(include='number').columns)\n",
    "    result_numeric.remove('is_sm_ips_ports')\n",
    "    result_numeric.remove('is_ftp_login')\n",
    "\n",
    "    #Using numeric columns to scale them using Standard Scaler\n",
    "    data[result_numeric] = scaler.transform(data[result_numeric])\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardizing the train data\n",
    "X_train = scale_data(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving some important parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving some important parameters\n",
    "saved_parameters['columns'] = X_train.columns\n",
    "saved_parameters['num_col'] = result_numeric\n",
    "\n",
    "#From the features csv file we can see that these are categories that state feature can take\n",
    "saved_parameters['state_categories'] = ['ACC', 'CLO', 'CON', 'ECO', 'ECR', 'FIN', 'INT', 'MAS', 'PAR', 'REQ', 'RST', 'TST', 'TXD', 'URH', 'URN']\n",
    "\n",
    "#From the features csv file we can see that these are categories that service feature can take\n",
    "saved_parameters['service_categories'] =['http', 'ftp', 'smtp', 'ssh', 'dns', 'ftp-data' ,'irc']\n",
    "\n",
    "#proto one hot encoding categories\n",
    "saved_parameters['proto_categories'] = X_train['proto'].unique()\n",
    "\n",
    "#Saving the saved parameters dictionary in a pickle file\n",
    "pickle.dump(saved_parameters, open(os.path.join(saved_files_path,'saved_parameters.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical encoding - one hot encoding\n",
    "def categorical_encoding(data):\n",
    "    '''\n",
    "    This function one hot encodes service, proto and state categorical features\n",
    "    '''\n",
    "    saved_parameters = pickle.load(open(saved_files_path+'saved_parameters.pkl', 'rb'))\n",
    "    state_categories = saved_parameters['state_categories']\n",
    "    service_categories = saved_parameters['service_categories']\n",
    "    proto_categories = saved_parameters['proto_categories']\n",
    "\n",
    "    #For state feature\n",
    "    for i in state_categories:\n",
    "        data['state_'+i] = [1 if cat==i else 0 for cat in data['state'].values]\n",
    "\n",
    "    data = data.drop(['state'], axis=1)\n",
    "    \n",
    "    #For service feature\n",
    "    for i in service_categories:\n",
    "        data['service_'+i] = [1 if cat==i else 0 for cat in data['service'].values]\n",
    "\n",
    "    data = data.drop(['service'], axis=1)\n",
    "    \n",
    "    #For proto feature\n",
    "    for i in proto_categories:\n",
    "        data['proto_'+i] = [1 if cat==i else 0 for cat in data['proto'].values]\n",
    "\n",
    "    data = data.drop(['proto'], axis=1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the train data:  (2032034, 194)\n",
      "Shape of the test data:  (508009, 42)\n"
     ]
    }
   ],
   "source": [
    "#Applying the categorical encoding function on train dataset\n",
    "X_train = categorical_encoding(X_train)\n",
    "print(\"Shape of the train data: \",X_train.shape)\n",
    "print(\"Shape of the test data: \",X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving mode vals\n",
    "saved_mode_vals = {}\n",
    "\n",
    "for i in X_train.columns:\n",
    "    saved_mode_vals[i] = X_train[i].mode()[0]\n",
    "    \n",
    "pickle.dump(saved_mode_vals, open(os.path.join(saved_files_path,'saved_mode_vals.pkl'),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleanup(data, set_name = \"data\"):\n",
    "    '''\n",
    "    This function applies various techniques to clean the dataset.\n",
    "    '''\n",
    "    saved_parameters = pickle.load(open(saved_files_path+'saved_parameters.pkl', 'rb'))\n",
    "    saved_mode_vals = pickle.load(open(saved_files_path+'saved_mode_vals.pkl', 'rb'))\n",
    "    \n",
    "    #Cleaning the data\n",
    "    for col in data.columns:\n",
    "        mod = saved_mode_vals[col]\n",
    "        \n",
    "        #Fixing Binary data columns\n",
    "        if col in saved_parameters['binary_cols']:\n",
    "            data[col][data[col] > 1] = mod\n",
    "        \n",
    "        #Replacing '-' with \"None\" for service feature\n",
    "        data[col] = data[col].replace(to_replace='-', value=\"None\")\n",
    "        #Filling null values\n",
    "        data[col] = data[col].fillna(value=mod)\n",
    "        #Filling empty values\n",
    "        data[col] = data[col].replace(to_replace=' ', value=mod)\n",
    "\n",
    "    #Fixing the data types of data\n",
    "    data_types_to_correct = list(set(data.select_dtypes(exclude='number').columns) - set(saved_parameters['cat_cols']))\n",
    "    \n",
    "    for col in data_types_to_correct:\n",
    "        data[col] = data[col].astype(float)\n",
    "        \n",
    "    print(\"The shape of {} after data cleanup is: {}\".format(set_name, data.shape))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Training data after data cleanup is: (2032034, 194)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_cleanup(X_train, 'Training data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now preparing the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(508009, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>sloss</th>\n",
       "      <th>dloss</th>\n",
       "      <th>service</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1444308</th>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dns</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188426</th>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.018467</td>\n",
       "      <td>2438</td>\n",
       "      <td>19186</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038228</th>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.031910</td>\n",
       "      <td>7820</td>\n",
       "      <td>15998</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281265</th>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>132</td>\n",
       "      <td>164</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dns</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383961</th>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.289009</td>\n",
       "      <td>4528</td>\n",
       "      <td>2872</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        proto state       dur  sbytes  dbytes  sttl  dttl  sloss  dloss  \\\n",
       "1444308   udp   CON  0.001221     146     178    31    29      0      0   \n",
       "2188426   tcp   FIN  0.018467    2438   19186    31    29      7     13   \n",
       "1038228   tcp   FIN  0.031910    7820   15998    31    29     30     32   \n",
       "281265    udp   CON  0.001005     132     164    31    29      0      0   \n",
       "2383961   tcp   FIN  0.289009    4528    2872    31    29      7      7   \n",
       "\n",
       "        service  ...  ct_flw_http_mthd  is_ftp_login  ct_ftp_cmd  ct_srv_src  \\\n",
       "1444308     dns  ...               NaN           NaN                       1   \n",
       "2188426       -  ...               NaN           NaN                       7   \n",
       "1038228       -  ...               0.0           0.0           0          13   \n",
       "281265      dns  ...               0.0           0.0           0           1   \n",
       "2383961       -  ...               NaN           NaN                       7   \n",
       "\n",
       "         ct_srv_dst  ct_dst_ltm  ct_src_ltm  ct_src_dport_ltm  \\\n",
       "1444308           2           4           2                 1   \n",
       "2188426           3           3           4                 1   \n",
       "1038228          11           9          10                 1   \n",
       "281265            6           2           6                 1   \n",
       "2383961           7           3           6                 1   \n",
       "\n",
       "         ct_dst_sport_ltm  ct_dst_src_ltm  \n",
       "1444308                 1               1  \n",
       "2188426                 1               4  \n",
       "1038228                 1               7  \n",
       "281265                  1               1  \n",
       "2383961                 1               8  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "X_test = X_test.drop('Unnamed: 0', axis=1)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of data after data cleanup is: (508009, 194)\n"
     ]
    }
   ],
   "source": [
    "def create_test_data(data):\n",
    "    '''\n",
    "    This function uses all the pipeline functions to create the test dataset\n",
    "    '''\n",
    "    #droping the index\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    #Dropping columns with high correlation\n",
    "    saved_parameters = pickle.load(open(saved_files_path+'saved_parameters.pkl', 'rb'))\n",
    "    #data = data.drop(saved_parameters['mandatory_to_drop'], axis=1)\n",
    "    data = data.drop(saved_parameters['cols_to_drop'], axis=1)\n",
    "    \n",
    "    #Had inconsistent datatype in train data\n",
    "    data['ct_ftp_cmd'] = data['ct_ftp_cmd'].replace(to_replace=' ', value=0).astype(float)\n",
    "    \n",
    "    #Generating new feature set 1\n",
    "    data['total_bytes'] = data['sbytes']+data['dbytes']\n",
    "    data['total_load'] = data['sload'] + data['dload']\n",
    "    \n",
    "    #Log1p transform\n",
    "    data = log1p_transform(data)\n",
    "    \n",
    "    #Scale transform\n",
    "    data = scale_data(data)\n",
    "    \n",
    "    #One hot encoding\n",
    "    data = categorical_encoding(data)\n",
    "    \n",
    "    #Cleaning data\n",
    "    data = data_cleanup(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "#Applying the entire data pipeline to test dataset\n",
    "X_test = create_test_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(508009, 194)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sttl</th>\n",
       "      <th>swin</th>\n",
       "      <th>stcpb</th>\n",
       "      <th>dtcpb</th>\n",
       "      <th>smean</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>response_body_len</th>\n",
       "      <th>tcprtt</th>\n",
       "      <th>synack</th>\n",
       "      <th>ackdat</th>\n",
       "      <th>...</th>\n",
       "      <th>proto_esp</th>\n",
       "      <th>proto_stp</th>\n",
       "      <th>proto_wb-expak</th>\n",
       "      <th>proto_compaq-peer</th>\n",
       "      <th>proto_rvd</th>\n",
       "      <th>proto_ip</th>\n",
       "      <th>proto_aris</th>\n",
       "      <th>proto_rtp</th>\n",
       "      <th>proto_igmp</th>\n",
       "      <th>proto_udt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.425838</td>\n",
       "      <td>-1.196075</td>\n",
       "      <td>-0.887140</td>\n",
       "      <td>-0.887240</td>\n",
       "      <td>-0.337423</td>\n",
       "      <td>-0.237366</td>\n",
       "      <td>-0.089758</td>\n",
       "      <td>-0.135307</td>\n",
       "      <td>-0.128343</td>\n",
       "      <td>-0.121503</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.425838</td>\n",
       "      <td>0.836077</td>\n",
       "      <td>0.061320</td>\n",
       "      <td>1.586638</td>\n",
       "      <td>-0.396687</td>\n",
       "      <td>-0.237366</td>\n",
       "      <td>-0.089758</td>\n",
       "      <td>-0.121729</td>\n",
       "      <td>-0.109606</td>\n",
       "      <td>-0.115590</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.425838</td>\n",
       "      <td>0.836077</td>\n",
       "      <td>0.381132</td>\n",
       "      <td>1.893360</td>\n",
       "      <td>-0.396687</td>\n",
       "      <td>-0.237366</td>\n",
       "      <td>-0.089758</td>\n",
       "      <td>-0.119451</td>\n",
       "      <td>-0.106046</td>\n",
       "      <td>-0.115045</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.425838</td>\n",
       "      <td>-1.196075</td>\n",
       "      <td>-0.887140</td>\n",
       "      <td>-0.887240</td>\n",
       "      <td>-0.383517</td>\n",
       "      <td>-0.237366</td>\n",
       "      <td>-0.089758</td>\n",
       "      <td>-0.135307</td>\n",
       "      <td>-0.128343</td>\n",
       "      <td>-0.121503</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.425838</td>\n",
       "      <td>0.836077</td>\n",
       "      <td>1.454779</td>\n",
       "      <td>-0.051558</td>\n",
       "      <td>0.327645</td>\n",
       "      <td>-0.237366</td>\n",
       "      <td>-0.089758</td>\n",
       "      <td>-0.120371</td>\n",
       "      <td>-0.107063</td>\n",
       "      <td>-0.115716</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 194 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sttl      swin     stcpb     dtcpb     smean  trans_depth  \\\n",
       "0 -0.425838 -1.196075 -0.887140 -0.887240 -0.337423    -0.237366   \n",
       "1 -0.425838  0.836077  0.061320  1.586638 -0.396687    -0.237366   \n",
       "2 -0.425838  0.836077  0.381132  1.893360 -0.396687    -0.237366   \n",
       "3 -0.425838 -1.196075 -0.887140 -0.887240 -0.383517    -0.237366   \n",
       "4 -0.425838  0.836077  1.454779 -0.051558  0.327645    -0.237366   \n",
       "\n",
       "   response_body_len    tcprtt    synack    ackdat  ...  proto_esp  proto_stp  \\\n",
       "0          -0.089758 -0.135307 -0.128343 -0.121503  ...          0          0   \n",
       "1          -0.089758 -0.121729 -0.109606 -0.115590  ...          0          0   \n",
       "2          -0.089758 -0.119451 -0.106046 -0.115045  ...          0          0   \n",
       "3          -0.089758 -0.135307 -0.128343 -0.121503  ...          0          0   \n",
       "4          -0.089758 -0.120371 -0.107063 -0.115716  ...          0          0   \n",
       "\n",
       "   proto_wb-expak  proto_compaq-peer  proto_rvd  proto_ip  proto_aris  \\\n",
       "0               0                  0          0         0           0   \n",
       "1               0                  0          0         0           0   \n",
       "2               0                  0          0         0           0   \n",
       "3               0                  0          0         0           0   \n",
       "4               0                  0          0         0           0   \n",
       "\n",
       "   proto_rtp  proto_igmp  proto_udt  \n",
       "0          0           0          0  \n",
       "1          0           0          0  \n",
       "2          0           0          0  \n",
       "3          0           0          0  \n",
       "4          0           0          0  \n",
       "\n",
       "[5 rows x 194 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matching test data columns with train data columns\n",
    "all(X_train.columns == X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving all the files to disk to use later\n",
    "pickle.dump((X_train, y_train), open(saved_files_path+'final_train_fe.pkl', 'wb'))\n",
    "pickle.dump((X_test, y_test), open(saved_files_path+'final_test_fe.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
